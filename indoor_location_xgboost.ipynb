{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "indoor_location_xgboost.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikhilno1/indoor-location/blob/master/indoor_location_xgboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "e7Zup4Ka4b4h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse\n",
        "import pickle\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, LabelBinarizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OaRBkw-h4b4o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"https://raw.githubusercontent.com/nikhilno1/indoor-location/master/sample_data.csv\", sep=',')    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CCmV6vyB4b4s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "ce5551f5-63c7-4595-c908-d118a80b55d1"
      },
      "cell_type": "code",
      "source": [
        "# Create training and validation sets\n",
        "sz = df.shape\n",
        "train_df = df.iloc[:int(sz[0] * 0.7), :]\n",
        "test_df = df.iloc[int(sz[0] * 0.7):, :]\n",
        "\n",
        "# Keep only the srs columns\n",
        "train_df1 = train_df.iloc[:, :32]\n",
        "\n",
        "# Separate X & Y for training\n",
        "train_X = train_df1.values\n",
        "train_Y1 = train_df.iloc[:, 32].values\n",
        "train_Y2 = train_df.iloc[:, 33].values\n",
        "\n",
        "test_df1 = test_df.iloc[:, :32]\n",
        "\n",
        "# Separate X & Y for test\n",
        "test_X = test_df1.values\n",
        "test_Y1 = test_df.iloc[:, 32].values\n",
        "test_Y2 = test_df.iloc[:, 33].values\n",
        "\n",
        "classes = df.ue_loc_1.unique()\n",
        "num_classes = df.ue_loc_1.nunique()\n",
        "\n",
        "# integer encode\n",
        "le = LabelEncoder()\n",
        "train_Y = le.fit_transform(train_Y1.tolist())\n",
        "test_Y = le.fit_transform(test_Y1.tolist())\n",
        "\n",
        "xg_train = xgb.DMatrix(train_X, label=train_Y)\n",
        "xg_test = xgb.DMatrix(test_X, label=test_Y)\n",
        "\n",
        "# setup parameters for xgboost\n",
        "param = {}\n",
        "# use softmax multi-class classification\n",
        "param['objective'] = 'multi:softmax'\n",
        "# scale weight of positive examples\n",
        "param['eta'] = 0.1\n",
        "param['max_depth'] = 6\n",
        "param['silent'] = 1\n",
        "param['nthread'] = 4\n",
        "param['num_class'] = num_classes\n",
        "\n",
        "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
        "num_round = 5\n",
        "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
        "#bst.dump_model('dump.nice.txt', 'myfeatmap.txt')\n",
        "# get prediction\n",
        "pred = bst.predict(xg_test)\n",
        "error_rate = np.sum(pred != test_Y) / test_Y.shape[0]\n",
        "print('Test error using softmax = {}'.format(error_rate))\n",
        "\n",
        "# do the same thing again, but output probabilities\n",
        "param['objective'] = 'multi:softprob'\n",
        "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
        "# Note: this convention has been changed since xgboost-unity\n",
        "# get prediction, this is in 1D array, need reshape to (ndata, nclass)\n",
        "pred_prob = bst.predict(xg_test).reshape(test_Y.shape[0], num_classes)\n",
        "pred_label = np.argmax(pred_prob, axis=1)\n",
        "error_rate = np.sum(pred_label != test_Y) / test_Y.shape[0]\n",
        "print('Test error using softprob = {}'.format(error_rate))\n",
        "\n",
        "# # Serialize both the pipeline and binarizer to disk.\n",
        "# with open('my_sklearn_objects.pkl', 'wb') as f:\n",
        "#     pickle.dump((bst, le), f)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\ttrain-merror:0.001488\ttest-merror:0.00284\n",
            "[1]\ttrain-merror:0.000812\ttest-merror:0.00284\n",
            "[2]\ttrain-merror:0.001488\ttest-merror:0.00284\n",
            "[3]\ttrain-merror:0.000812\ttest-merror:0.00284\n",
            "[4]\ttrain-merror:0.000812\ttest-merror:0.00284\n",
            "Test error using softmax = 0.002840012622278321\n",
            "[0]\ttrain-merror:0.001488\ttest-merror:0.00284\n",
            "[1]\ttrain-merror:0.000812\ttest-merror:0.00284\n",
            "[2]\ttrain-merror:0.001488\ttest-merror:0.00284\n",
            "[3]\ttrain-merror:0.000812\ttest-merror:0.00284\n",
            "[4]\ttrain-merror:0.000812\ttest-merror:0.00284\n",
            "Test error using softprob = 0.002840012622278321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jGnEG8644b41",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load Model"
      ]
    },
    {
      "metadata": {
        "id": "tAFFod8H4b41",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "bfdd31a3-794a-45b8-ac78-6e4e7472b536"
      },
      "cell_type": "code",
      "source": [
        "# Hydrate the serialized objects.\n",
        "#with open('my_sklearn_objects.pkl', 'rb') as f:\n",
        "#    bst1, le1 = pickle.load(f)\n",
        "    \n",
        "data = [100.0,99.0,124,128,95,190,98,92,158,96,97,141,99,97,99,151,98,96,99,100,99,94,124,148,98,98,120,100,95,99,98.0,100]\n",
        "data = [float(val) for val in data]\n",
        "dtest = xgb.DMatrix(data)\n",
        "test_pred = bst.predict(dtest)\n",
        "test_label = np.argmax(test_pred, axis=1)\n",
        "final_pred = le.inverse_transform(test_label)\n",
        "final_pred[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rp6'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "E2OSUjbk4b48",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}